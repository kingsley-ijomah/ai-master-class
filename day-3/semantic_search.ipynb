{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HyWoEkQo1t3S",
        "outputId": "b7fe01e9-54fd-47fc-b5f4-acafa75c84a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymongo\n",
            "  Downloading pymongo-4.15.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (2025.10.5)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading pymongo-4.15.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.8.0 pymongo-4.15.4\n"
          ]
        }
      ],
      "source": [
        "!pip install pymongo certifi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import certifi\n",
        "from pymongo import MongoClient\n",
        "from google.colab import userdata\n",
        "\n",
        "db_user = userdata.get('db_user')\n",
        "db_password = userdata.get('db_password')\n",
        "db_name = userdata.get('db_name')\n",
        "\n",
        "# Construct the connection string using credentials from Colab secrets\n",
        "# Ensure your MongoDB Atlas cluster name and domain are correct\n",
        "connection_string = f\"mongodb+srv://{db_user}:{db_password}@ai-master.rmxat2v.mongodb.net/?appName={db_name}\"\n",
        "\n",
        "# Initialize the MongoDB client and get the database instance\n",
        "client = MongoClient(connection_string, tls=True, tlsCAFile=certifi.where())\n",
        "db = client[db_name]\n",
        "print(\"Connected to the database.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr_G-p1U2GjX",
        "outputId": "b3cc44ea-6124-4a02-8c68-4c07139f61b5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to the database.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Tokenize sample text to show how text is split before vectorization\n",
        "\n",
        "sample_text = \"How to bake an apple pie\"\n",
        "\n",
        "# Simple whitespace tokenization (can compare with more advanced methods)\n",
        "tokens = sample_text.split()\n",
        "\n",
        "print(\"Original text:\", sample_text)\n",
        "print(\"Tokens:\", tokens)\n",
        "\n",
        "# You can try with different sample texts as well\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEo9pyRC2cyB",
        "outputId": "ae705f7b-ef20-44fb-8172-e680bb4f8ebb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: How to bake an apple pie\n",
            "Tokens: ['How', 'to', 'bake', 'an', 'apple', 'pie']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Sample documents to vectorize (can be your tokens joined back or other short texts)\n",
        "documents = [\n",
        "    \"how to bake an apple pie\",\n",
        "    \"apple launches new iphone\",\n",
        "    \"bananas are rich in potassium\"\n",
        "]\n",
        "\n",
        "# Initialize the TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the documents to get TF-IDF vectors\n",
        "tfidf_vectors = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Show feature names (vocabulary)\n",
        "print(\"Vocabulary:\", vectorizer.get_feature_names_out())\n",
        "\n",
        "# Show TF-IDF vectors as dense arrays for illustration\n",
        "for i, vec in enumerate(tfidf_vectors.toarray()):\n",
        "    print(f\"Document {i} vector:\")\n",
        "    print(vec)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Uz_ojvXK2yCL",
        "outputId": "90c28d4a-301c-4a74-8b27-c346b90b6ae0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['an' 'apple' 'are' 'bake' 'bananas' 'how' 'in' 'iphone' 'launches' 'new'\n",
            " 'pie' 'potassium' 'rich' 'to']\n",
            "Document 0 vector:\n",
            "[0.42339448 0.32200242 0.         0.42339448 0.         0.42339448\n",
            " 0.         0.         0.         0.         0.42339448 0.\n",
            " 0.         0.42339448]\n",
            "Document 1 vector:\n",
            "[0.         0.40204024 0.         0.         0.         0.\n",
            " 0.         0.52863461 0.52863461 0.52863461 0.         0.\n",
            " 0.         0.        ]\n",
            "Document 2 vector:\n",
            "[0.        0.        0.4472136 0.        0.4472136 0.        0.4472136\n",
            " 0.        0.        0.        0.        0.4472136 0.4472136 0.       ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank_bm25\n",
        "\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "# Tokenize documents (here, just split on whitespace for the demo)\n",
        "tokenized_corpus = [doc.split() for doc in documents]\n",
        "\n",
        "# Initialize BM25\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "# Query example (gets BM25 scores for \"apple pie\")\n",
        "query = \"apple pie\".split()\n",
        "bm25_scores = bm25.get_scores(query)\n",
        "\n",
        "print(\"BM25 scores for query ['apple', 'pie']:\", bm25_scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RNM73hqA3Zhy",
        "outputId": "ba8b3f71-59ff-4a3b-9e8d-69d82b9a267c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rank_bm25) (2.0.2)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n",
            "BM25 scores for query ['apple', 'pie']: [0.5690718  0.12028861 0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the sentence-transformers library silently\n",
        "!pip install -q sentence-transformers\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "# Load a small, fast semantic embedding model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Define richer documents to index with metadata\n",
        "rich_documents = [\n",
        "    {\n",
        "        \"doc_id\": \"1\",\n",
        "        \"title\": \"Apple launches latest iPhone\",\n",
        "        \"description\": \"Apple unveils iPhone 15 with improved battery life and camera system.\",\n",
        "        \"category\": \"technology\",\n",
        "        \"source\": \"https://apple.com/news/iphone15\",\n",
        "        \"created_at\": datetime(2025, 9, 12),\n",
        "        \"author\": \"Apple Newsroom\"\n",
        "    },\n",
        "    {\n",
        "        \"doc_id\": \"2\",\n",
        "        \"title\": \"Bananas help regulate blood pressure\",\n",
        "        \"description\": \"Nutritionists recommend bananas for their potassium content which supports heart health.\",\n",
        "        \"category\": \"health\",\n",
        "        \"source\": \"https://healthnews.com/bananas-benefits\",\n",
        "        \"created_at\": datetime(2025, 6, 30),\n",
        "        \"author\": \"Health News\"\n",
        "    },\n",
        "    {\n",
        "        \"doc_id\": \"3\",\n",
        "        \"title\": \"Guide to baking an apple pie\",\n",
        "        \"description\": \"Step-by-step instructions to baking a delicious classic apple pie.\",\n",
        "        \"category\": \"cooking\",\n",
        "        \"source\": \"https://cookingblog.com/apple-pie\",\n",
        "        \"created_at\": datetime(2024, 11, 10),\n",
        "        \"author\": \"Cooking Blog\"\n",
        "    },\n",
        "    {\n",
        "        \"doc_id\": \"4\",\n",
        "        \"title\": \"Google updates search algorithm\",\n",
        "        \"description\": \"Google's latest algorithm update improves semantic understanding for better search results.\",\n",
        "        \"category\": \"technology\",\n",
        "        \"source\": \"https://googleblog.com/search-update\",\n",
        "        \"created_at\": datetime(2025, 10, 5),\n",
        "        \"author\": \"Google Blog\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Prepare the text data for embedding by concatenating title and description\n",
        "texts = [doc['title'] + \". \" + doc['description'] for doc in rich_documents]\n",
        "\n",
        "# Generate semantic embeddings for the prepared texts\n",
        "embeddings = model.encode(texts)\n",
        "\n",
        "# Set printing options for cleaner vector display if needed\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "\n",
        "# Show the shape of the generated embeddings\n",
        "print(\"Shape of embeddings:\", embeddings.shape)\n",
        "\n",
        "# Show a sample embedding vector for the first document (rounded)\n",
        "print(\"Sample semantic vector for first document:\")\n",
        "print(embeddings[0])\n",
        "\n",
        "# Attach embeddings as lists to the respective document entries for MongoDB\n",
        "for doc, embed in zip(rich_documents, embeddings):\n",
        "    doc['embedding'] = embed.tolist()\n",
        "\n",
        "# create a collection called vector_documents\n",
        "vector_collection = db[\"vector_documents\"]\n",
        "\n",
        "# Insert the new rich documents with semantic vectors into the collection\n",
        "result = vector_collection.insert_many(rich_documents)\n",
        "print(f\"Inserted {len(result.inserted_ids)} new rich documents with semantic vectors.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "o3f5OJox4gRW",
        "outputId": "8bc1a20b-7c3c-4d85-a568-11c6f52acfb3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of embeddings: (4, 384)\n",
            "Sample semantic vector for first document:\n",
            "[-0.068  0.058  0.089 -0.037  0.061 -0.033 -0.07   0.011  0.023  0.069\n",
            "  0.108  0.017 -0.072  0.078  0.028  0.05   0.102 -0.052 -0.012 -0.022\n",
            "  0.001 -0.043  0.035  0.02   0.092  0.09  -0.045 -0.101 -0.087 -0.054\n",
            "  0.009 -0.021  0.066 -0.009 -0.01  -0.05  -0.026 -0.006  0.06  -0.01\n",
            " -0.067  0.005 -0.033  0.08   0.06   0.009 -0.012  0.019 -0.013 -0.017\n",
            "  0.01   0.012  0.032  0.022  0.015 -0.022 -0.067 -0.017  0.087 -0.013\n",
            " -0.005  0.038 -0.063  0.024 -0.003 -0.007 -0.026 -0.047  0.007  0.045\n",
            " -0.014  0.004  0.038 -0.053 -0.029  0.045  0.035  0.013 -0.024 -0.018\n",
            "  0.028 -0.002  0.001 -0.036  0.022 -0.043 -0.047  0.014 -0.014 -0.031\n",
            " -0.125  0.08  -0.044 -0.003 -0.008  0.    -0.022 -0.039 -0.094 -0.012\n",
            "  0.076 -0.039  0.06   0.005  0.01  -0.102 -0.017 -0.033  0.04   0.092\n",
            "  0.073 -0.028 -0.064 -0.061  0.072  0.033 -0.074  0.063  0.084  0.022\n",
            " -0.005 -0.019 -0.041 -0.028 -0.097 -0.028 -0.017 -0.    -0.005 -0.008\n",
            " -0.031  0.067 -0.008 -0.074  0.036  0.068 -0.007 -0.02  -0.022 -0.053\n",
            " -0.034 -0.011  0.082 -0.04  -0.05  -0.024  0.028 -0.006  0.026 -0.058\n",
            " -0.053 -0.002  0.006 -0.031  0.058  0.016 -0.02  -0.013 -0.028  0.031\n",
            " -0.02  -0.084 -0.006  0.064  0.133 -0.023  0.079 -0.023  0.004  0.021\n",
            " -0.031  0.019  0.127  0.076 -0.086  0.028 -0.019 -0.015 -0.011 -0.021\n",
            "  0.013 -0.054 -0.072  0.048  0.013 -0.003  0.002  0.033 -0.043 -0.02\n",
            " -0.049  0.025 -0.057  0.053  0.015 -0.013 -0.067  0.149 -0.024  0.044\n",
            "  0.012 -0.059  0.057  0.086 -0.038 -0.023  0.017  0.08  -0.021  0.047\n",
            "  0.015 -0.011  0.045 -0.106 -0.052 -0.027  0.031  0.13   0.015 -0.023\n",
            " -0.019  0.07   0.039 -0.     0.038 -0.041 -0.054 -0.026 -0.003 -0.039\n",
            " -0.041  0.073 -0.057 -0.04  -0.002  0.004  0.015  0.089  0.027  0.008\n",
            " -0.061 -0.08  -0.038  0.09   0.029 -0.001  0.003 -0.012 -0.014 -0.\n",
            "  0.01   0.05   0.007 -0.128  0.078 -0.13   0.019 -0.011  0.009  0.075\n",
            " -0.045 -0.073  0.025 -0.036  0.072  0.026  0.009  0.021 -0.001  0.067\n",
            " -0.032  0.037 -0.004 -0.011  0.002 -0.038 -0.072  0.028 -0.117 -0.019\n",
            "  0.026  0.047  0.065  0.009  0.112  0.03  -0.002 -0.109 -0.065 -0.087\n",
            " -0.04   0.002 -0.049  0.072 -0.086 -0.043 -0.023 -0.022 -0.009  0.01\n",
            "  0.039 -0.003 -0.015 -0.055  0.102  0.071  0.017 -0.029  0.05   0.065\n",
            "  0.029 -0.077  0.054  0.107 -0.009 -0.022 -0.05   0.074 -0.095 -0.\n",
            "  0.017 -0.003  0.049 -0.032  0.014 -0.008  0.014  0.076  0.163 -0.04\n",
            "  0.046 -0.085 -0.061  0.05   0.069  0.036  0.065  0.023  0.055 -0.042\n",
            " -0.053  0.058  0.024 -0.041  0.043 -0.005 -0.034 -0.097  0.037 -0.015\n",
            "  0.002  0.035  0.056 -0.002 -0.047  0.029 -0.075 -0.018  0.065 -0.016\n",
            " -0.033  0.009 -0.038 -0.018 -0.062 -0.085  0.034 -0.088 -0.007  0.03\n",
            " -0.105 -0.087  0.081 -0.011  0.078  0.007  0.015 -0.043 -0.045  0.013\n",
            "  0.077 -0.035  0.017  0.073]\n",
            "Inserted 4 new rich documents with semantic vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What this does:**  \n",
        "- Each document is stored with its original text and its 384-dimensional embedding as a list.\n",
        "- The collection is now ready for future vector search (semantic similarity query)."
      ],
      "metadata": {
        "id": "jGGpBgzY6kKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo.operations import SearchIndexModel\n",
        "\n",
        "# Correct vector index definition for MongoDB Atlas\n",
        "search_index_definition = {\n",
        "    \"mappings\": {\n",
        "        \"dynamic\": False,\n",
        "        \"fields\": {\n",
        "            \"embedding\": {\n",
        "                \"type\": \"knnVector\",        # Must be 'knnVector' for vector search!\n",
        "                \"dimensions\": 384,          # Set to your embedding length\n",
        "                \"similarity\": \"cosine\"      # Use 'cosine' or 'euclidean', etc.\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "index_name = \"my_vector_index\"\n",
        "\n",
        "# Check for existing search indexes with that name (idempotent creation)\n",
        "try:\n",
        "    indexes = vector_collection.list_search_indexes()\n",
        "    existing_names = [idx[\"name\"] for idx in indexes]\n",
        "    if index_name in existing_names:\n",
        "        print(f\"Search index '{index_name}' already exists (idempotent, so skipping creation).\")\n",
        "    else:\n",
        "        search_index_model = SearchIndexModel(\n",
        "            definition=search_index_definition,\n",
        "            name=index_name,\n",
        "            type=\"search\"\n",
        "        )\n",
        "        result = vector_collection.create_search_index(model=search_index_model)\n",
        "        print(f\"Created vector search index '{index_name}': {result}\")\n",
        "except Exception as e:\n",
        "    print(\"Error checking or creating search index.\")\n",
        "    print(\"Exception message:\", e)\n",
        "\n",
        "# Comments:\n",
        "# - The field type for Atlas vector search must be 'knnVector', not just 'vector'.\n",
        "# - All other logic remains the same; 'dimensions' and 'similarity' must match your data/model.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eGzK9RE6yNc",
        "outputId": "aaf15f25-7fd6-438c-d66f-4a1634185be6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created vector search index 'my_vector_index': my_vector_index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step: Semantic vector search query example cell\n",
        "\n",
        "# Define the query text to search semantically\n",
        "search_text = \"latest smartphone features\"\n",
        "\n",
        "# Use the same embedding model to create the query vector\n",
        "query_embedding = model.encode([search_text])[0].tolist()\n",
        "\n",
        "# Define the MongoDB Atlas aggregation pipeline using knnBeta for vector search\n",
        "pipeline = [\n",
        "    {\n",
        "        \"$search\": {\n",
        "            \"index\": \"my_vector_index\",  # Name of your vector index\n",
        "            \"knnBeta\": {\n",
        "                \"vector\": query_embedding,  # Query embedding vector\n",
        "                \"path\": \"embedding\",        # Field to compare vectors against\n",
        "                \"k\": 3                      # Number of closest documents to return\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# Run the aggregation pipeline on your vector collection to get top matches\n",
        "results = list(vector_collection.aggregate(pipeline))\n",
        "\n",
        "# Display matching documents with some context\n",
        "print(f\"Top {len(results)} semantic search results for query: '{search_text}'\\n\")\n",
        "for idx, doc in enumerate(results):\n",
        "    print(f\"Result {idx + 1}:\")\n",
        "    print(f\"Title: {doc['title']}\")\n",
        "    print(f\"Description: {doc['description']}\")\n",
        "    print(f\"Category: {doc.get('category', 'N/A')}\")\n",
        "    print(f\"Source URL: {doc.get('source', 'N/A')}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuciabszDQy7",
        "outputId": "354347c1-cc13-4c36-c471-f8783760a263"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 semantic search results for query: 'latest smartphone features'\n",
            "\n",
            "Result 1:\n",
            "Title: Apple launches latest iPhone\n",
            "Description: Apple unveils iPhone 15 with improved battery life and camera system.\n",
            "Category: technology\n",
            "Source URL: https://apple.com/news/iphone15\n",
            "--------------------------------------------------\n",
            "Result 2:\n",
            "Title: Apple launches latest iPhone\n",
            "Description: Apple unveils iPhone 15 with improved battery life and camera system.\n",
            "Category: technology\n",
            "Source URL: https://apple.com/news/iphone15\n",
            "--------------------------------------------------\n",
            "Result 3:\n",
            "Title: Bananas help regulate blood pressure\n",
            "Description: Nutritionists recommend bananas for their potassium content which supports heart health.\n",
            "Category: health\n",
            "Source URL: https://healthnews.com/bananas-benefits\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the search text query you want to perform a hybrid semantic + filtered search on\n",
        "search_text = \"apple smartphone\"\n",
        "\n",
        "# Generate the embedding vector for the query text using the same pre-trained model used for indexing\n",
        "query_embedding = model.encode([search_text])[0].tolist()\n",
        "\n",
        "# Build the MongoDB aggregation pipeline:\n",
        "# - First, perform vector similarity search using the 'knnBeta' operator on the 'embedding' field\n",
        "# - Then, apply a classic MongoDB filter stage to restrict the results to documents in the 'technology' category\n",
        "pipeline = [\n",
        "    {\n",
        "        \"$search\": {\n",
        "            \"index\": \"my_vector_index\",  # Name of your existing Atlas vector index\n",
        "            \"knnBeta\": {\n",
        "                \"vector\": query_embedding,  # The query vector to find nearest neighbors\n",
        "                \"path\": \"embedding\",        # Field in your documents containing the vectors\n",
        "                \"k\": 5                      # Number of nearest neighbors (top results) to return\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"$match\": {\n",
        "            \"category\": \"technology\"       # Metadata filter to limit results to technology-related documents\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# Execute the aggregation pipeline on your MongoDB collection\n",
        "results = list(vector_collection.aggregate(pipeline))\n",
        "\n",
        "# Display the number of results and iterate over each matched document to print details\n",
        "print(f\"Top {len(results)} hybrid semantic + filtered results for '{search_text}':\\n\")\n",
        "for i, doc in enumerate(results):\n",
        "    print(f\"Result {i+1}: Title: {doc['title']}, Category: {doc['category']}\")\n",
        "    print(f\"Description: {doc['description']}\\n\")\n",
        "\n",
        "# Comments:\n",
        "# - This pipeline combines semantic vector similarity search with traditional metadata filtering.\n",
        "# - The '$search' stage with 'knnBeta' performs efficient nearest neighbor search based on vector embeddings.\n",
        "# - The subsequent '$match' stage filters down the semantic search results to documents matching specific metadata criteria.\n",
        "# - This approach is powerful for scenarios where semantic relevance and explicit domain constraints must apply simultaneously.\n",
        "# - Adjust 'k' and filter conditions to tune the breadth and specificity of results.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sW_oFMNIgh5",
        "outputId": "bb9a318b-1da8-4e57-effd-7419ef2dbd65"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 hybrid semantic + filtered results for 'apple smartphone':\n",
            "\n",
            "Result 1: Title: Apple launches latest iPhone, Category: technology\n",
            "Description: Apple unveils iPhone 15 with improved battery life and camera system.\n",
            "\n",
            "Result 2: Title: Apple launches latest iPhone, Category: technology\n",
            "Description: Apple unveils iPhone 15 with improved battery life and camera system.\n",
            "\n",
            "Result 3: Title: Google updates search algorithm, Category: technology\n",
            "Description: Google's latest algorithm update improves semantic understanding for better search results.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}